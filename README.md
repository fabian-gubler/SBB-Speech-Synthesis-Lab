# Introduction

Automatic Speech Recognition (ASR) is pivotal in numerous applications, from transcription services to voice assistants. However, it faces challenges regarding accent diversity and data limitation. Our project seeks to overcome these hurdles by using synthetic data augmentation, a technique effective in various machine learning tasks.

Our synthetic data, generated using Text-to-Speech (TTS) technology, expands our training set's diversity and variety. By introducing more variations in speaker characteristics and commandos, it enhances the ability of our ASR model to generalize to unseen data.

We utilized the Conformer-CTC model, known for its efficacy in ASR tasks. We investigated its performance with different levels of synthetic data integrated into the training set, comparing it against a baseline model and one trained only on human-recorded samples.

The outcomes of our experiments demonstrate the potential of synthetic data augmentation in improving ASR performance, thereby offering a substantial contribution to the robustness and effectiveness of real-world ASR systems.

## Contents of this Repository

This repository contains the following files and directories, which are crucial for understanding and replicating the project:

- **/**
    - `generate_available_voice.py`: Fetches a list of available voices from the Azure voice pool for synthetic data generation.
    - `generate_commandos.py`: Used for the rule-based generation of commandos.
    - `generate_input_combinations.py`: Creates various combinations of text, voices, and styles for speech generation.
    - `generate_speech.py`: A script that does the following:
        1. Creates SSML (Speech Synthesis Markup Language) strings based on input.
        2. Feeds the SSML strings into the speech synthesizer.
        3. Calculates the duration of each synthesized speech.
        4. Adds an entry to the manifest file for each synthesized speech.

- **/conformer/**
    - `experiments.py`: The main batch script responsible for training the Conformer-CTC model. This script manages the entire training process including loading the dataset, initializing the model, setting up the optimizer, and handling the training loop.
    - `generate_manifest.py`: Accepts all the samples and generates several manifest files for training, validation, and testing. These manifest files serve as the primary data source for the `experiments.py` script.
    - `eval.py`: Loads .nemo model files for evaluation. While this is used mainly for debugging, extensive logging is done automatically through weights and biases integration for tracking the model's performance over epochs.

- **/data/**: Holds all necessary output files needed for speech generation. This includes combinations of text, voices, and styles (generated by `generate_input_combinations.py`), commandos (generated by `generate_commandos.py`), and available voices (fetched by `generate_available_voice.py`).

# Installation & Usage

## Generating Speech samples

Steps

- Use the settings-example.json (rename to settings.json necessary) file to modify the metadata for the speech generation
process. You need to add your api of azure speech services.

- Install vagrant and packages of libvirtd client

- Standard vagrant setup process (installing - vagrant up etc.). the provision.sh
   should run automatically and install all necessary packages of the virtual
   machine


- Run "main.py" (takes in all necessary files) for a guided step by step process



# SBB Speech Synthesis Lab

Generate Description (GPT::Batch Script)

Components

- Files needed to generate data: Include ppt files
- Conformer files and subcomponents

Setup

- Generate the data: Vagrant
- Run the model: requirements.txt

## (TBD) Contents of this README
1. General Overview / Description
2. Detailed description of components
3. Setup / Installation
