# Introduction
This project aims to enhance the performance of Automatic Speech Recognition (ASR) systems by incorporating synthetic data in the training process.

Automatic Speech Recognition is a field of study that involves training machines to recognize and translate spoken language into written text. ASR technology plays a crucial role in various applications such as transcription services, voice assistants, and automated customer services. Despite significant advancements in this field, handling diverse accents and limited data remain persistent challenges that hinder the performance of ASR systems.

Our goal in this project was to overcome these challenges by using synthetic data augmentation. Data augmentation has proven to be an effective strategy in various machine learning tasks to improve model performance, and we believe it holds great promise for ASR as well.

Our synthetic data, which was created using Text-to-Speech (TTS) technology, expands the diversity and variety of our training set. It introduces more variations in speaker characteristics and commandos, thereby allowing our ASR model to better generalize to unseen data.

In our work, we focused on the Conformer-CTC model due to its suitability for ASR tasks. We evaluated the model's performance with varying levels of synthetic data added to the training set and compared it against a baseline model as well as a model trained with only human-recorded samples.

The results from our experiments offer compelling evidence of the potential of synthetic data augmentation in improving ASR performance. This project, therefore, provides a meaningful contribution towards making ASR systems more robust and effective in real-world applications.

## Contents of this Repository

This repository contains the following files and directories, which are crucial for understanding and replicating the project:

- **/**
    - `generate_available_voice.py`: Fetches a list of available voices from the Azure voice pool for synthetic data generation.
    - `generate_commandos.py`: Used for the rule-based generation of commandos.
    - `generate_input_combinations.py`: Creates various combinations of text, voices, and styles for speech generation.
    - `generate_speech.py`: A script that does the following:
        1. Creates SSML (Speech Synthesis Markup Language) strings based on input.
        2. Feeds the SSML strings into the speech synthesizer.
        3. Calculates the duration of each synthesized speech.
        4. Adds an entry to the manifest file for each synthesized speech.

- **/conformer/**
    - `experiments.py`: The main batch script responsible for training the Conformer-CTC model. This script manages the entire training process including loading the dataset, initializing the model, setting up the optimizer, and handling the training loop.
    - `generate_manifest.py`: Accepts all the samples and generates several manifest files for training, validation, and testing. These manifest files serve as the primary data source for the `experiments.py` script.
    - `eval.py`: Loads .nemo model files for evaluation. While this is used mainly for debugging, extensive logging is done automatically through weights and biases integration for tracking the model's performance over epochs.

- **/data/**: Holds all necessary output files needed for speech generation. This includes combinations of text, voices, and styles (generated by `generate_input_combinations.py`), commandos (generated by `generate_commandos.py`), and available voices (fetched by `generate_available_voice.py`).

# Installation & Usage

## Generating Speech samples

Steps

- Use the settings-example.json (rename to settings.json necessary) file to modify the metadata for the speech generation
process. You need to add your api of azure speech services.

- Install vagrant and packages of libvirtd client

- Standard vagrant setup process (installing - vagrant up etc.). the provision.sh
   should run automatically and install all necessary packages of the virtual
   machine


- Run "main.py" (takes in all necessary files) for a guided step by step process



# SBB Speech Synthesis Lab

Generate Description (GPT::Batch Script)

Components

- Files needed to generate data: Include ppt files
- Conformer files and subcomponents

Setup

- Generate the data: Vagrant
- Run the model: requirements.txt

## (TBD) Contents of this README
1. General Overview / Description
2. Detailed description of components
3. Setup / Installation
